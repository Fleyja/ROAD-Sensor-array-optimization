{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data import get_data, DF\n",
    "# from src.models import MLP\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "\n",
    "from src.models import MLP, train, evaluate, epoch_time, MyDataset\n",
    "\n",
    "import time, copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.000703113446890762\n",
    "weight_decay = 0.00006156146508441857\n",
    "# select = 'Ridge+GA'\n",
    "select = 'manual+10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = list(range(10))\n",
    "# recipes = [0,3,7]\n",
    "dataset_train = MyDataset(pd.read_csv(f\"data/select/{select}_train.csv\"), recipes)\n",
    "dataset_test = MyDataset(pd.read_csv(f\"data/select/{select}_test.csv\"), recipes)\n",
    "test_size = int(0.5 * len(dataset_test))\n",
    "test_data, valid_data = torch.utils.data.random_split(\n",
    "    dataset_test, [len(dataset_test) - test_size, test_size]\n",
    ")\n",
    "BATCH_SIZE = 128\n",
    "train_iterator = data.DataLoader(dataset_train,shuffle=True,batch_size=BATCH_SIZE)\n",
    "valid_iterator = data.DataLoader(valid_data,batch_size=BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3 * len(recipes), [72, 39, 10], 3, 'tanh').to(device)\n",
    "# model.load_state_dict(torch.load(f\"./{select}-model.pt\"))\n",
    "# best_model = copy.deepcopy(model)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'models/{select}.pt')\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train Loss: {train_loss:.5f} | Val. Loss: {valid_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
